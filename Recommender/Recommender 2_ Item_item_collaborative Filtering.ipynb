{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1934be0f",
   "metadata": {},
   "source": [
    "### Item Item Collaborative Filtering\n",
    "Item-item collaborative filtering is a popular technique used in recommendation systems, similar to user-user collaborative filtering but with a key difference. While user-user collaborative filtering focuses on similarities between users, item-item collaborative filtering focuses on the relationships between items. Hereâ€™s an intuitive way to understand it:\n",
    "\n",
    "Analogy: Book Recommendations in a Library\n",
    "Imagine you're in a library looking for a book to read. You find a book you enjoyed in the past, let's say \"Harry Potter and the Sorcerer's Stone\". Now, instead of asking people what other books they like (as you would in user-user collaborative filtering), you look for books that people who liked \"Harry Potter and the Sorcerer's Stone\" also enjoyed. You might find that many of these people also liked \"The Chronicles of Narnia\". Therefore, the system recommends \"The Chronicles of Narnia\" to you.\n",
    "\n",
    "How Item-Item Collaborative Filtering Works\n",
    "Item Similarity Calculation: The system calculates similarities between items based on user ratings. For example, if many users who like \"Movie A\" also like \"Movie B\", then \"Movie A\" and \"Movie B\" are considered similar.\n",
    "\n",
    "Rating Predictions: To predict a user's interest in an item they haven't rated, the system looks at items similar to those the user has already rated highly. It aggregates the ratings of these similar items to make a prediction.\n",
    "\n",
    "Recommendation Generation: The system recommends items with the highest predicted ratings, which the user hasn't rated or seen yet.\n",
    "\n",
    "Key Concepts\n",
    "Item Profiles: The system builds a profile for each item based on user ratings, rather than building profiles for each user.\n",
    "Neighborhood Selection: It selects a \"neighborhood\" of similar items to those that the target user likes or rates highly.\n",
    "Weighted Averages: Predicted ratings for an item are often computed as the weighted average of ratings from similar items.\n",
    "Advantages Over User-User Collaborative Filtering\n",
    "Stability: Item preferences tend to change less frequently than user preferences, making the item-item approach potentially more stable over time.\n",
    "Scalability: In many cases, there are fewer items than users, making item-item collaborative filtering more scalable.\n",
    "Limitations\n",
    "Cold Start for New Items: New items with few or no ratings are difficult to recommend because their similarity to other items is not yet known.\n",
    "Long Tail Problem: Some items may have very few ratings, making it hard to ascertain their similarity to other items accurately.\n",
    "In essence, item-item collaborative filtering is akin to making recommendations based on the principle, \"If you liked this, you might also like these,\" focusing on the relationships between items themselves based on user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48122ae0",
   "metadata": {},
   "source": [
    "### Mathematical Intuition\n",
    "\n",
    "Certainly! The mathematical intuition behind item-item collaborative filtering involves understanding the relationships between different items based on user preferences. Here's a breakdown of how this works mathematically:\n",
    "\n",
    "1. Item Similarity Calculation\n",
    "The first step in item-item collaborative filtering is to calculate the similarity between items. This is done using users' ratings of these items. The idea is that if a large group of users rate two items similarly, these items are likely to be similar.\n",
    "\n",
    "Commonly used metrics for similarity include cosine similarity, Pearson correlation, or adjusted cosine similarity.\n",
    "\n",
    "Cosine Similarity: Here, each item is represented as a vector in an N-dimensional user space (where N is the number of users), and the similarity is the cosine of the angle between these two vectors. The formula is similar to user-user but transposed:\n",
    "\n",
    "similarity\n",
    "\n",
    "Adjusted Cosine Similarity: This is a variation of cosine similarity which subtracts the user's average rating to normalize for different user rating scales.\n",
    "\n",
    "adjusted_similarity\n",
    "\n",
    "2. Prediction of Ratings\n",
    "Once item similarities are known, you can predict a user's rating for an item based on their ratings for similar items. The predicted rating for an item is usually a weighted average of the user's ratings on similar items:\n",
    "\n",
    "\n",
    "3. Key Mathematical Concepts\n",
    "Matrix Representation: User-item interactions are represented in a matrix where rows represent users and columns represent items.\n",
    "Sparsity: The user-item matrix is typically sparse as not all users rate all items.\n",
    "Normalization: Adjusted cosine similarity accounts for different user rating scales, which helps normalize the data.\n",
    "Conclusion\n",
    "Mathematically, item-item collaborative filtering is about understanding the relationships between items in a high-dimensional user space. By calculating the similarity between items based on user ratings, and then using these similarities to predict a user's rating for an item, the system can make personalized recommendations. This method is particularly effective in environments where the number of items is smaller than the number of users, making it more manageable computationally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55627f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {\n",
    "    'User1': {'Matrix': 5, 'Inception': 3, 'Avengers': 2},\n",
    "    'User2': {'Matrix': 3, 'Inception': 5, 'Avengers': 1},\n",
    "    'User3': {'Matrix': 4, 'Inception': 4, 'Avengers': 3},\n",
    "    'User4': {'Matrix': 3, 'Avengers': 4},\n",
    "    'User5': {'Inception': 4, 'Avengers': 5}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021a0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the ratings dictionary to an item-user matrix\n",
    "movies = sorted({movie for user_ratings in ratings.values() for movie in user_ratings})\n",
    "user_ids = sorted(ratings.keys())\n",
    "item_user_matrix = np.zeros((len(movies), len(user_ids)))\n",
    "\n",
    "for i, movie in enumerate(movies):\n",
    "    for j, user in enumerate(user_ids):\n",
    "        item_user_matrix[i, j] = ratings[user].get(movie, 0)\n",
    "\n",
    "# Calculate cosine similarity between items\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Compute the similarity matrix\n",
    "similarity_matrix = np.zeros((len(movies), len(movies)))\n",
    "\n",
    "for i in range(len(movies)):\n",
    "    for j in range(len(movies)):\n",
    "        similarity_matrix[i, j] = cosine_similarity(item_user_matrix[i], item_user_matrix[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b6fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User1 for 'Avengers': 3.9529230472583268\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(user, movie):\n",
    "    movie_index = movies.index(movie)\n",
    "    user_index = user_ids.index(user)\n",
    "    similar_movies = similarity_matrix[movie_index]\n",
    "\n",
    "    weighted_sum = 0\n",
    "    sum_of_similarities = 0\n",
    "\n",
    "    for i, similarity in enumerate(similar_movies):\n",
    "        if i != movie_index and item_user_matrix[i, user_index] > 0:\n",
    "            weighted_sum += similarity * item_user_matrix[i, user_index]\n",
    "            sum_of_similarities += similarity\n",
    "\n",
    "    if sum_of_similarities == 0:\n",
    "        return 0\n",
    "\n",
    "    return weighted_sum / sum_of_similarities\n",
    "\n",
    "# Example: Predict the rating for User1 for 'Avengers'\n",
    "predicted_rating = predict_rating('User1', 'Avengers')\n",
    "print(f\"Predicted rating for User1 for 'Avengers': {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a551e4",
   "metadata": {},
   "source": [
    "## Using Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ae96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Sample dataset\n",
    "ratings = {\n",
    "    'User1': {'Matrix': 5, 'Inception': 3, 'Avengers': 2, 'Toy Story': 4},\n",
    "    'User2': {'Matrix': 3, 'Inception': 5, 'Avengers': 1, 'Toy Story': 3},\n",
    "    'User3': {'Matrix': 4, 'Inception': 4, 'Avengers': 3, 'Toy Story': 5},\n",
    "    'User4': {'Inception': 4, 'Avengers': 5, 'Toy Story': 2},\n",
    "    'User5': {'Matrix': 3, 'Avengers': 4, 'Toy Story': 3}\n",
    "}\n",
    "\n",
    "# Function to split data into train and test sets\n",
    "def split_data(data, test_ratio=0.2):\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for user, movies in data.items():\n",
    "        for movie, rating in movies.items():\n",
    "            if random.random() < test_ratio:\n",
    "                test_data.setdefault(user, {})[movie] = rating\n",
    "            else:\n",
    "                train_data.setdefault(user, {})[movie] = rating\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "train_ratings, test_ratings = split_data(ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03cb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_user_matrix(ratings_data):\n",
    "    movies = sorted(set(movie for user_ratings in ratings_data.values() for movie in user_ratings))\n",
    "    users = sorted(ratings_data)\n",
    "    matrix = np.zeros((len(movies), len(users)))\n",
    "\n",
    "    for movie_index, movie in enumerate(movies):\n",
    "        for user_index, user in enumerate(users):\n",
    "            matrix[movie_index, user_index] = ratings_data.get(user, {}).get(movie, 0)\n",
    "\n",
    "    return matrix, movies, users\n",
    "\n",
    "train_matrix, movies, users = create_item_user_matrix(train_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8a9489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0\n",
    "\n",
    "def calculate_similarity_matrix(matrix):\n",
    "    num_items = matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((num_items, num_items))\n",
    "\n",
    "    for i in range(num_items):\n",
    "        for j in range(num_items):\n",
    "            similarity_matrix[i, j] = cosine_similarity(matrix[i], matrix[j])\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(train_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e4eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User1 for 'Inception': 4.7309454833996005\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(user, movie, train_matrix, similarity_matrix, movies, users):\n",
    "    if movie not in movies or user not in users:\n",
    "        return 0\n",
    "\n",
    "    movie_index = movies.index(movie)\n",
    "    user_index = users.index(user)\n",
    "\n",
    "    weighted_sum = 0\n",
    "    sum_of_weights = 0\n",
    "\n",
    "    for i in range(len(movies)):\n",
    "        if train_matrix[i, user_index] > 0 and i != movie_index:\n",
    "            weighted_sum += similarity_matrix[movie_index, i] * train_matrix[i, user_index]\n",
    "            sum_of_weights += abs(similarity_matrix[movie_index, i])\n",
    "\n",
    "    return weighted_sum / sum_of_weights if sum_of_weights > 0 else 0\n",
    "\n",
    "# Example: Predict rating for a user and movie in the test set\n",
    "user = list(test_ratings.keys())[0]\n",
    "movie = list(test_ratings[user].keys())[0]\n",
    "predicted_rating = predict_rating(user, movie, train_matrix, similarity_matrix, movies, users)\n",
    "print(f\"Predicted rating for {user} for '{movie}': {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21f8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error: 1.5233096188916009\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test_ratings, train_matrix, similarity_matrix, movies, users):\n",
    "    total_error = 0\n",
    "    count = 0\n",
    "\n",
    "    for user, user_ratings in test_ratings.items():\n",
    "        for movie, actual_rating in user_ratings.items():\n",
    "            predicted = predict_rating(user, movie, train_matrix, similarity_matrix, movies, users)\n",
    "            total_error += abs(predicted - actual_rating)\n",
    "            count += 1\n",
    "\n",
    "    return total_error / count if count > 0 else 0\n",
    "\n",
    "error = evaluate_model(test_ratings, train_matrix, similarity_matrix, movies, users)\n",
    "print(f\"Average prediction error: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c61b2",
   "metadata": {},
   "source": [
    "## Using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07814da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample dataset\n",
    "ratings = {\n",
    "    'User1': {'Matrix': 5, 'Inception': 3, 'Avengers': 2, 'Toy Story': 4},\n",
    "    'User2': {'Matrix': 3, 'Inception': 5, 'Avengers': 1, 'Toy Story': 3},\n",
    "    'User3': {'Matrix': 4, 'Inception': 4, 'Avengers': 3, 'Toy Story': 5},\n",
    "    'User4': {'Inception': 4, 'Avengers': 5, 'Toy Story': 2},\n",
    "    'User5': {'Matrix': 3, 'Avengers': 4, 'Toy Story': 3}\n",
    "}\n",
    "\n",
    "# Convert the ratings dictionary to a user-item matrix\n",
    "movies = sorted({movie for user_ratings in ratings.values() for movie in user_ratings})\n",
    "user_ids = sorted(ratings.keys())\n",
    "item_user_matrix = np.zeros((len(movies), len(user_ids)))\n",
    "\n",
    "for i, movie in enumerate(movies):\n",
    "    for j, user in enumerate(user_ids):\n",
    "        item_user_matrix[i, j] = ratings[user].get(movie, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fa1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_matrix = cosine_similarity(item_user_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d12fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User1 for 'Toy Story': 3.415017908317992\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(user_id, movie_id):\n",
    "    user_index = user_ids.index(user_id)\n",
    "    movie_index = movies.index(movie_id)\n",
    "\n",
    "    # Get similarity scores for the movie in question with all other movies\n",
    "    similarity_scores = item_similarity_matrix[movie_index]\n",
    "\n",
    "    # Multiply the similarity scores with the user's ratings\n",
    "    user_ratings = item_user_matrix[:, user_index]\n",
    "    weighted_ratings = similarity_scores * user_ratings\n",
    "\n",
    "    # Exclude the current movie's rating from the sum\n",
    "    weighted_ratings[movie_index] = 0\n",
    "    similarity_scores[movie_index] = 0\n",
    "\n",
    "    # Predict the rating: weighted sum of ratings divided by the sum of similarities\n",
    "    if np.sum(similarity_scores) > 0:\n",
    "        return np.sum(weighted_ratings) / np.sum(similarity_scores)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Example: Predict the rating for User1 for 'Toy Story'\n",
    "predicted_rating = predict_rating('User1', 'Toy Story')\n",
    "print(f\"Predicted rating for User1 for 'Toy Story': {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4d22c",
   "metadata": {},
   "source": [
    "## What is Cold Start Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fe1ee",
   "metadata": {},
   "source": [
    "The cold start problem is a common challenge in the field of recommendation systems. It refers to the difficulty that such systems face when they have to make accurate recommendations with little to no historical data available. This problem typically presents itself in two main scenarios:\n",
    "\n",
    "New User Cold Start: When a new user joins a platform, the system lacks data on this user's preferences and behaviors. Since collaborative filtering and other recommendation strategies heavily rely on past user interactions (like ratings, purchases, or viewing history), the system struggles to predict what this new user might like.\n",
    "\n",
    "New Item Cold Start: When a new item (such as a product, movie, or article) is added to the platform, there is initially little to no interaction data associated with this item. As a result, the system cannot easily recommend this new item to users because it lacks historical data on how users interact with it.\n",
    "\n",
    "Solutions to the Cold Start Problem\n",
    "Using Non-Collaborative Features: For new users, the system might use demographic data (like age, gender, location) or ask users to provide their preferences during sign-up (e.g., asking about favorite genres in a movie app). For new items, metadata like category, creator, or descriptive tags can be used.\n",
    "\n",
    "Hybrid Recommendation Systems: Combining collaborative filtering with content-based filtering or other methods can mitigate the cold start problem. For example, a recommendation system for movies might use the genres or actors of a movie (content-based features) in addition to user ratings (collaborative data).\n",
    "\n",
    "Utilizing Community Data: If other similar platforms exist, leveraging aggregated data from these platforms can jump-start recommendations.\n",
    "\n",
    "Exploration Techniques: Employing techniques like A/B testing or bandit algorithms can help the system quickly learn user preferences or the appeal of new items by intentionally introducing varied content to users.\n",
    "\n",
    "User Onboarding Processes: Engaging users in an interactive onboarding process where they rate or select items of interest can provide initial data points for personalized recommendations.\n",
    "\n",
    "Transfer Learning: If a recommendation system is being built in a domain related to an existing system (e.g., a new movie recommendation system by a company already running a book recommendation system), transfer learning can be applied to use knowledge gained in one domain for another.\n",
    "\n",
    "Conclusion\n",
    "The cold start problem is a significant challenge in building effective recommendation systems. Addressing it requires a combination of creative strategies and the use of auxiliary information beyond just user-item interaction data. As the system accumulates more data over time, its ability to make accurate and personalized recommendations typically improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586046f0",
   "metadata": {},
   "source": [
    "## What is long Tail Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336ff33",
   "metadata": {},
   "source": [
    "The \"long tail\" problem in the context of recommendation systems refers to the challenge of handling the vast number of items that are infrequently purchased, rated, or interacted with, but collectively make up a significant portion of the total demand or interest. This concept is derived from the \"long tail\" distribution, where a large number of items have low popularity or sales, as opposed to a small number of items with very high popularity.\n",
    "\n",
    "Understanding the Long Tail\n",
    "In many markets, particularly those online, a small number of items (known as the \"head\") account for a large portion of sales or interactions, while a much larger number of items (the \"long tail\") have relatively few sales or interactions each. However, the aggregate of these \"long tail\" items can be significant.\n",
    "\n",
    "Challenges in Recommendation Systems\n",
    "Visibility of Long Tail Items: Popular items tend to get recommended more often, reinforcing their popularity, while less popular items remain obscure. This can create a feedback loop where the rich get richer (popular items get more popular), and the long tail items remain in obscurity.\n",
    "\n",
    "Data Sparsity: Long tail items have fewer interactions, leading to sparser data. This makes it more challenging for collaborative filtering systems to find patterns or similarities, as there's less user interaction data to analyze.\n",
    "\n",
    "User Personalization: While focusing on popular items might satisfy a broad user base, it can neglect niche interests. Users with unique tastes might not find these recommendations appealing.\n",
    "\n",
    "Solutions to Address the Long Tail Problem\n",
    "Content-Based Filtering: This approach recommends items based on their characteristics, rather than user interactions, which can help in surfacing long tail items that are similar to a user's previous interests.\n",
    "\n",
    "Hybrid Systems: Combining collaborative filtering with content-based filtering can balance the focus between popular and long tail items.\n",
    "\n",
    "Diversity in Recommendations: Deliberately including diverse and less popular items in recommendations can expose users to a wider range of products or content.\n",
    "\n",
    "Exploratory Algorithms: Using algorithms that explore less popular items more frequently can increase the visibility of long tail items.\n",
    "\n",
    "Personalized Marketing: Targeted marketing strategies can help in promoting long tail items to relevant segments of users.\n",
    "\n",
    "Balanced Metrics: Employing evaluation metrics that give weight to the recommendation of long tail items can incentivize systems to include them more often.\n",
    "\n",
    "Conclusion\n",
    "The long tail problem highlights the importance of not just focusing on the most popular items but also recognizing the value of the vast number of less popular items. Addressing this issue is crucial for providing personalized and diverse recommendations and for tapping into niche markets, which can be particularly beneficial for businesses and users alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a6203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
